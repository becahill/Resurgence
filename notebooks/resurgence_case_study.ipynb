{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resurgence Case Study Notebook\n",
        "\n",
        "This notebook demonstrates an end-to-end risk workflow:\n",
        "1. Data ingestion for a sample multi-asset portfolio\n",
        "2. Monte Carlo simulation for VaR/CVaR\n",
        "3. Loss-distribution and rolling-VaR visualization\n",
        "4. VaR/CVaR interpretation from a backtest summary\n",
        "5. Deterministic auditor flagging with structured anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "from datetime import date\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from resurgence_py.auditor import LLMAuditor\n",
        "from resurgence_py.engine import simulate_regime_var_cvar_python\n",
        "from resurgence_py.models import CrashVolProfile, DataPullConfig, PortfolioSeries, RiskMetrics\n",
        "from resurgence_py.visualization import plot_loss_distribution, plot_rolling_var\n",
        "from validation.backtest import BacktestConfig, run_backtest_on_returns, write_backtest_results\n",
        "\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "artifact_dir = Path('notebooks/artifacts')\n",
        "artifact_dir.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Data Ingestion\n",
        "\n",
        "The notebook tries to pull daily adjusted-close returns for `SPY/QQQ/TLT/GLD`.\n",
        "If network data is unavailable, it falls back to a deterministic synthetic return series.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def load_portfolio_returns() -> tuple[pd.Series, str]:\n",
        "    try:\n",
        "        import yfinance as yf\n",
        "\n",
        "        tickers = ['SPY', 'QQQ', 'TLT', 'GLD']\n",
        "        prices = yf.download(\n",
        "            tickers=tickers,\n",
        "            start='2018-01-01',\n",
        "            end='2026-02-21',\n",
        "            interval='1d',\n",
        "            auto_adjust=False,\n",
        "            progress=False,\n",
        "            group_by='column',\n",
        "            threads=True,\n",
        "        )\n",
        "        if prices.empty:\n",
        "            raise RuntimeError('Empty yfinance payload')\n",
        "\n",
        "        close = prices['Adj Close'] if 'Adj Close' in prices.columns.get_level_values(0) else prices['Close']\n",
        "        returns = close.pct_change().dropna(how='any')\n",
        "        weights = np.array([0.40, 0.25, 0.20, 0.15], dtype=np.float64)\n",
        "        portfolio_returns = returns.mul(weights, axis=1).sum(axis=1)\n",
        "        portfolio_returns.name = 'portfolio_return'\n",
        "        source = 'yfinance'\n",
        "    except Exception as exc:  # noqa: BLE001\n",
        "        rng = np.random.default_rng(12)\n",
        "        portfolio_returns = pd.Series(\n",
        "            rng.normal(loc=0.00035, scale=0.011, size=1_000),\n",
        "            index=pd.bdate_range(start='2020-01-02', periods=1_000),\n",
        "            name='portfolio_return',\n",
        "        )\n",
        "        source = f'synthetic fallback ({exc.__class__.__name__})'\n",
        "\n",
        "    return portfolio_returns.astype(np.float64), source\n",
        "\n",
        "\n",
        "portfolio_returns, data_source = load_portfolio_returns()\n",
        "print(f'data source: {data_source}')\n",
        "print(f'observations: {len(portfolio_returns)}')\n",
        "portfolio_returns.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Simulation Run\n",
        "\n",
        "Use the most recent 252 trading days as the calibration window and run a regime-switching Monte Carlo simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "window_returns = portfolio_returns.iloc[-252:].to_numpy(dtype=np.float64)\n",
        "\n",
        "risk, losses = simulate_regime_var_cvar_python(\n",
        "    returns=window_returns.tolist(),\n",
        "    confidence_level=0.95,\n",
        "    simulations=50_000,\n",
        "    horizon_days=10,\n",
        "    transition_matrix=[[0.92, 0.04, 0.04], [0.10, 0.80, 0.10], [0.18, 0.14, 0.68]],\n",
        "    state_vol_multipliers=[0.70, 1.85, 1.00],\n",
        "    state_drift_adjustments=[0.0003, -0.0008, 0.0],\n",
        "    initial_state=2,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(f\"VaR(95%): {risk.var:.4%}\")\n",
        "print(f\"CVaR(95%): {risk.cvar:.4%}\")\n",
        "print(f\"Mean loss: {risk.mean_loss:.4%}\")\n",
        "print(f\"Loss stddev: {risk.loss_stddev:.4%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Loss Distribution Visualization\n",
        "\n",
        "Render the histogram from simulated losses and the rolling VaR/CVaR chart from backtest observations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "try:\n",
        "    loss_plot = plot_loss_distribution(\n",
        "        losses=losses,\n",
        "        output_path=artifact_dir / 'loss_distribution.png',\n",
        "        bins=60,\n",
        "        confidence_level=0.95,\n",
        "    )\n",
        "    print(f'loss distribution chart: {loss_plot}')\n",
        "except RuntimeError as exc:  # matplotlib optional\n",
        "    print(exc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Rolling VaR/CVaR Backtest + Interpretation\n",
        "\n",
        "Run a historical rolling backtest, write CSV/JSON outputs, and interpret breach behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "backtest_config = BacktestConfig(\n",
        "    tickers=['SPY', 'QQQ', 'TLT', 'GLD'],\n",
        "    weights=[0.40, 0.25, 0.20, 0.15],\n",
        "    confidence_level=0.95,\n",
        "    rolling_window=126,\n",
        "    method='historical',\n",
        "    simulations=5_000,\n",
        "    horizon_days=1,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "observations, summary = run_backtest_on_returns(\n",
        "    portfolio_returns=portfolio_returns,\n",
        "    config=backtest_config,\n",
        ")\n",
        "\n",
        "csv_path, json_path = write_backtest_results(\n",
        "    observations=observations,\n",
        "    summary=summary,\n",
        "    output_dir=artifact_dir / 'validation',\n",
        ")\n",
        "\n",
        "print(f'backtest rows: {summary.observation_count}')\n",
        "print(f'breaches: {summary.breaches} ({summary.breach_rate:.2%})')\n",
        "print(f'expected breach rate: {summary.expected_breach_rate:.2%}')\n",
        "print(f'Kupiec p-value: {summary.kupiec_pof.p_value:.4f}')\n",
        "if summary.christoffersen.p_value is not None:\n",
        "    print(f'Christoffersen p-value: {summary.christoffersen.p_value:.4f}')\n",
        "print(f'csv output: {csv_path}')\n",
        "print(f'json output: {json_path}')\n",
        "\n",
        "try:\n",
        "    rolling_plot = plot_rolling_var(observations, artifact_dir / 'rolling_var.png')\n",
        "    print(f'rolling VaR chart: {rolling_plot}')\n",
        "except RuntimeError as exc:  # matplotlib optional\n",
        "    print(exc)\n",
        "\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        'metric': [\n",
        "            'mean_predicted_var',\n",
        "            'mean_predicted_cvar',\n",
        "            'mean_realized_loss',\n",
        "            'breach_rate',\n",
        "            'kupiec_p_value',\n",
        "        ],\n",
        "        'value': [\n",
        "            summary.mean_predicted_var,\n",
        "            summary.mean_predicted_cvar,\n",
        "            summary.mean_realized_loss,\n",
        "            summary.breach_rate,\n",
        "            summary.kupiec_pof.p_value,\n",
        "        ],\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Auditor Flag Example\n",
        "\n",
        "Create a stressed metrics payload to trigger deterministic anomaly checks and inspect the structured anomaly report.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "stressed_risk = RiskMetrics(\n",
        "    var=max(risk.var * 0.70, 1e-6),\n",
        "    cvar=max(risk.var * 0.50, 1e-6),  # intentionally below VaR to force a critical anomaly\n",
        "    mean_loss=1.15,\n",
        "    loss_stddev=1.10,\n",
        "    confidence_level=risk.confidence_level,\n",
        "    simulations=risk.simulations,\n",
        "    horizon_days=risk.horizon_days,\n",
        "    estimated_drift=risk.estimated_drift,\n",
        "    estimated_volatility=2.5,\n",
        "    sharpe_ratio=9.2,\n",
        "    max_loss_zscore=13.5,\n",
        ")\n",
        "\n",
        "portfolio = PortfolioSeries(\n",
        "    returns=portfolio_returns.tail(252).tolist(),\n",
        "    annualized_volatility=float(np.std(portfolio_returns.tail(252), ddof=1) * np.sqrt(252.0)),\n",
        "    observation_count=min(252, len(portfolio_returns)),\n",
        ")\n",
        "\n",
        "crash_profile = CrashVolProfile(\n",
        "    volatility_2008=0.45,\n",
        "    volatility_2020=0.55,\n",
        "    sample_size_2008=252,\n",
        "    sample_size_2020=252,\n",
        ")\n",
        "\n",
        "pull_config = DataPullConfig(\n",
        "    start_date=date(2018, 1, 1),\n",
        "    end_date=date(2026, 2, 21),\n",
        "    request_timeout_s=20.0,\n",
        ")\n",
        "\n",
        "auditor = LLMAuditor(model_name='gpt-4o-mini', allow_live_llm=False)\n",
        "audit_report = asyncio.run(\n",
        "    auditor.run(\n",
        "        risk=stressed_risk,\n",
        "        portfolio=portfolio,\n",
        "        crash_profile=crash_profile,\n",
        "        losses=losses,\n",
        "        pull_config=pull_config,\n",
        "        rerun_count=0,\n",
        "        max_reruns=2,\n",
        "    )\n",
        ")\n",
        "\n",
        "print(f\"severity: {audit_report.severity}\")\n",
        "print(f\"flagged: {audit_report.flagged}\")\n",
        "print(f\"requires rerun: {audit_report.requires_rerun}\")\n",
        "print(f\"summary: {audit_report.summary}\")\n",
        "\n",
        "pd.DataFrame([anomaly.model_dump() for anomaly in audit_report.anomalies]).head(20)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}